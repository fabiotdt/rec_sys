{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data loading and cleaning\n",
    "2. Object Segmentation\n",
    "    1. U-Net\n",
    "    2. YOLO seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/fabiotdt/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/humansintheloop/teeth-segmentation-on-dental-x-ray-images\n"
     ]
    }
   ],
   "source": [
    "# Download the data from Kaggle and unzip it\n",
    "\n",
    "import kaggle\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "kaggle.api.dataset_download_files('humansintheloop/teeth-segmentation-on-dental-x-ray-images', path='.', unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import json\n",
    "\n",
    "def create_directories(base_dir):\n",
    "\n",
    "    os.makedirs(os.path.join(base_dir,'images'), exist_ok=True)         # Images dir\n",
    "    os.makedirs(os.path.join(base_dir,'labels'), exist_ok=True)         # Labels dir\n",
    "\n",
    "    subdirs = [\n",
    "    \"images/train\", \n",
    "    \"images/test\", \n",
    "    \"images/valid\",\n",
    "    \"labels/train\", \n",
    "    \"labels/test\", \n",
    "    \"labels/valid\"]\n",
    "\n",
    "    # Create directories\n",
    "    for subdir in subdirs:\n",
    "        os.makedirs(os.path.join(base_dir, subdir), exist_ok=True)\n",
    "        \n",
    "def convert_annotation(label_file, image_w, image_h):\n",
    "    \n",
    "    with open(label_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    new_label_file = label_file.replace('.jpg.json', '.txt')\n",
    "\n",
    "    with open(new_label_file, 'w') as f:\n",
    "\n",
    "        for obj in data['objects']:\n",
    "\n",
    "            tooth = obj['classTitle']           # Tooth label\n",
    "            points = obj['points']['exterior']  # Polygon points\n",
    "            yolo_seg = []\n",
    "\n",
    "            yolo_seg.append(tooth)\n",
    " \n",
    "            for x, y in points:\n",
    "                norm_x = x / image_w\n",
    "                norm_y = y / image_h\n",
    "                yolo_seg.append(f\"{norm_x:.6f},{norm_y:.6f}\")  # Format to 6 decimal places\n",
    "\n",
    "            # Write the class and normalized polygon points to the file\n",
    "            f.write(f\"{tooth} \" + \" \".join(yolo_seg) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test split created\n",
      "Train data: 478\n",
      "Test data: 60\n",
      "Valid data: 60\n",
      "Directories created\n",
      "Train data converted\n",
      "Test data converted\n",
      "Valid data converted\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset complient to YOLO format\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "base_dir = 'teeth_segmentation'\n",
    "\n",
    "train_data, temp_data = train_test_split(os.listdir('Teeth Segmentation PNG/d2/img'), test_size=0.2, random_state=42)\n",
    "test_data, valid_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data = [os.path.join('Teeth Segmentation PNG/d2/img', image) for image in train_data]\n",
    "test_data = [os.path.join('Teeth Segmentation PNG/d2/img', image) for image in test_data]\n",
    "valid_data = [os.path.join('Teeth Segmentation PNG/d2/img', image) for image in valid_data]\n",
    "\n",
    "print(f'Train test split created')\n",
    "print(f'Train data: {len(train_data)}')\n",
    "print(f'Test data: {len(test_data)}')\n",
    "print(f'Valid data: {len(valid_data)}')\n",
    "\n",
    "create_directories(base_dir)\n",
    "\n",
    "print(f'Directories created')\n",
    "\n",
    "for el in train_data:\n",
    "\n",
    "    img = Image.open(el)\n",
    "    convert_annotation(el.replace('img', 'ann')+'.json', img.size[0], img.size[1])\n",
    "\n",
    "    shutil.move(el, os.path.join(base_dir, 'images/train'))\n",
    "    shutil.move(el.replace('img', 'ann').replace('.jpg', '.txt'), os.path.join(base_dir, 'labels/train'))\n",
    "\n",
    "print(f'Train data converted')\n",
    "\n",
    "for el in test_data:\n",
    "\n",
    "    img = Image.open(el)    \n",
    "    convert_annotation(el.replace('img','ann')+'.json', img.size[0], img.size[1])\n",
    "\n",
    "    shutil.move(el, os.path.join(base_dir, 'images/test'))\n",
    "    shutil.move(el.replace('img', 'ann').replace('.jpg', '.txt'), os.path.join(base_dir, 'labels/test'))\n",
    "\n",
    "print(f'Test data converted')\n",
    "\n",
    "for el in valid_data:\n",
    "    \n",
    "    img = Image.open(el)    \n",
    "    convert_annotation(el.replace('img', 'ann')+'.json', img.size[0], img.size[1])\n",
    "\n",
    "    shutil.move(el, os.path.join(base_dir, 'images/valid'))\n",
    "    shutil.move(el.replace('img', 'ann').replace('.jpg', '.txt'), os.path.join(base_dir, 'labels/valid'))\n",
    "\n",
    "print(f'Valid data converted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TeethDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, base_dir, transform=None):\n",
    "        \n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images_dir = os.path.join(base_dir, 'images')\n",
    "        self.labels_dir = os.path.join(base_dir, 'labels')\n",
    "\n",
    "        self.images = os.listdir(self.images_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path = os.path.join(self.images_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.labels_dir, self.images[idx].replace('.jpg', '.txt'))\n",
    "\n",
    "        image = Image.open(img_path)\n",
    "        label = open(label_path, 'r').read().strip()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((416, 416)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = TeethDataset(base_dir, transform=transform)\n",
    "test_dataset = TeethDataset(base_dir, transform=transform)\n",
    "valid_dataset = TeethDataset(base_dir, transform=transform)\n",
    "\n",
    "# PLot a sample image with the \n",
    "image, label = train_dataset[0]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image[0].permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "for seg_mask in label:\n",
    "\n",
    "    seg_mask = seg_mask.split(' ')\n",
    "    tooth = seg_mask[0]\n",
    "    points = seg_mask[1:]\n",
    "\n",
    "    points = [float(point) for point in points]\n",
    "\n",
    "    x = points[::2]\n",
    "    y = points[1::2]\n",
    "\n",
    "    plt.fill(x, y, edgecolor='r', fill=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the architecture of a base U-net\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder(x)\n",
    "        x2 = self.middle(x1)\n",
    "        x = self.decoder(x2)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMplement IuO to compute the goodness of the model prediction\n",
    "\n",
    "def IoU(pred, target):\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "\n",
    "    return intersection / (union + 1e-6) # Add a small value to avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement combined BCE + Dice loss\n",
    "from torch import nn\n",
    "\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "        \n",
    "        #self.bce_loss = nn.BCEWithLogitsLoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "        self.img_size = image_size\n",
    "\n",
    "    def compute_loss(self, predictions, targets):\n",
    "        \n",
    "        for pred, target in zip(predictions, targets):\n",
    "\n",
    "            pred_class = pred[0]\n",
    "            pred_mask = pred[1:]\n",
    "\n",
    "            target_class = target[0]\n",
    "            target_mask = target[1:]\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            intersection = (pred * target).sum()\n",
    "            union = pred.sum() + target.sum() - intersection\n",
    "\n",
    "            dice_loss = 1 - (2 * intersection) / (union + 1e-6)\n",
    "            bce_loss = self.bce_loss(pred, target)\n",
    "\n",
    "            return bce_loss + dice_loss\n",
    "        tooth_class = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the fit loop\n",
    "\n",
    "def train_fn(model, train_loader, optimizer, criterion, device, phase):\n",
    "    \n",
    "    if phase == 'train':\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    runnign_loss = 0.0\n",
    "    running_IoU = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        runnign_loss += loss.item()\n",
    "        running_IoU += IoU(model(images), tooth_mask)\n",
    "\n",
    "\n",
    "    return runnign_loss / len(train_loader), running_IoU / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the main training loop\n",
    "\n",
    "import torch\n",
    "\n",
    "device = 'cuda:0'\n",
    "batch_size = 32\n",
    "num_workers = 8\n",
    "lr = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "model = UNet(3, 1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = train_fn(model, train_loader, optimizer, criterion, device, 'train')\n",
    "    test_loss = train_fn(model, test_loader, optimizer, criterion, device, 'test')\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train Loss: {train_loss}, Test Loss: {test_loss}\")\n",
    "\n",
    "    loss_train.append(train_loss)\n",
    "    loss_test.append(test_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
